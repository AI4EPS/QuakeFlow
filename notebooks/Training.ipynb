{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chemical-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grave-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/weiqiang/.dotbot/cloud/quakeflow_wayne.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "meaningful-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(root_path: str = \"/tmp\"):\n",
    "# data_path = \"./\"\n",
    "# if True:\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    join_path = lambda x: os.path.join(root_path, x)\n",
    "    \n",
    "    ## download from gcp bucket\n",
    "    bucket_name = \"ncedc\"\n",
    "    def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(source_blob_name)\n",
    "        blob.download_to_filename(destination_file_name)\n",
    "        print(f\"download {source_blob_name} to {destination_file_name}.\")\n",
    "        \n",
    "    if not os.path.exists(join_path(\"catalogs/\")):\n",
    "        os.mkdir(join_path(\"catalogs/\"))\n",
    "    download_blob(\"ncedc\", \"catalogs/combined_phases.csv\", join_path(\"catalogs/combined_phases.csv\"))\n",
    "    catalog = pd.read_csv(join_path(\"catalogs/combined_phases.csv\"), sep=\"\\t\")\n",
    "    \n",
    "    index = catalog[\"event_index\"]\n",
    "    test = catalog[ index >= (index.max()-1) ]\n",
    "    valid = catalog[ (index < (index.max()-1)) & (index >= (index.max()-2)) ]\n",
    "    train = catalog[ (index < (index.max()-2)) & (index >= (index.max()-10)) ]\n",
    "    \n",
    "    for dataset in [\"train\", \"valid\", \"test\"]:\n",
    "        print(f\"Downloading {dataset} dataset...\")\n",
    "#         eval(dataset).to_csv(join_path(f\"{dataset}.csv\"), sep=\"\\t\")\n",
    "        eval(dataset)[\"itp\"] = eval(dataset)[\"p_idx\"]\n",
    "        eval(dataset)[\"its\"] = eval(dataset)[\"s_idx\"]\n",
    "        eval(dataset).to_csv(join_path(f\"{dataset}.csv\"), sep=\"\\t\")\n",
    "        print(f\"Save {join_path(f'{dataset}.csv')}\")\n",
    "        if not os.path.exists(join_path(f\"{dataset}_data/\")):\n",
    "            os.mkdir(join_path(f\"{dataset}_data/\"))\n",
    "        num = len(eval(dataset)[\"fname\"])\n",
    "        for i, fname in enumerate(eval(dataset)[\"fname\"]):\n",
    "            print(f\"{i+1}/{num}\",  end=' ')\n",
    "            download_blob(bucket_name, f\"data/{fname}\", join_path(f\"{dataset}_data/{fname}\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "static-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_dataset(root_path = \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "paperback-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset_op = comp.func_to_container_op(download_dataset, \n",
    "                                                base_image='python:3.7',\n",
    "                                                packages_to_install= [\n",
    "                                                    \"pandas\",\n",
    "                                                    \"google-cloud-storage\"\n",
    "                                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tough-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_op(root_path: str, \n",
    "                model_path: str,\n",
    "                batch_size: int = 2,\n",
    "                train_path: str = \"train_data\", \n",
    "                train_csv: str = \"train.csv\",\n",
    "                ):\n",
    "    \n",
    "    import os\n",
    "    join_path = lambda x: os.path.join(str(root_path), x)\n",
    "    return dsl.ContainerOp(name='PhaseNet training',\n",
    "                           image=\"zhuwq0/phasenet:latest\",\n",
    "#                            command=['sh', '-c'],\n",
    "#                            arguments=[\"mkdir /tmp/model && cp -r /opt/model/190703-214543 /tmp/model/190703-214543\"],\n",
    "                           command=['python'],\n",
    "                           arguments=[\n",
    "                               'train.py',\n",
    "                               '--epoch', 10,\n",
    "                               '--batch_size', batch_size,\n",
    "                               '--train_dir', join_path(str(train_path)),\n",
    "                               '--train_list', join_path(str(train_csv)),\n",
    "                               '--model_dir', join_path(str(model_path))\n",
    "                               ],\n",
    "#                            file_outputs = {\"model_path\": model_path}\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "accompanied-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PhaseNet/phasenet/train.py --epoch=10 --batch_size=2 --model_dir=models --train_list=train.csv --train_dir=train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "functioning-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_op(root_path: str, \n",
    "            model_path: str,\n",
    "            batch_size: int = 2,\n",
    "            test_path: str = \"test_data\", \n",
    "            test_csv: str = \"test.csv\",\n",
    "            result_path: str = \"results\"):\n",
    "    \n",
    "    import os\n",
    "    join_path = lambda x: os.path.join(str(root_path), x)\n",
    "    return dsl.ContainerOp(name='PhaseNet test',\n",
    "                           image=\"zhuwq0/phasenet:latest\",\n",
    "#                            command=['sh', '-c'],\n",
    "#                            arguments=[\"ls ./\"],\n",
    "                           command=['python'],\n",
    "                           arguments=[\n",
    "                               'train.py',\n",
    "                               '--mode', \"test\",\n",
    "                               '--model', join_path(str(model_path)),\n",
    "                               '--batch_size', batch_size,\n",
    "                               '--test_dir', join_path(str(test_path)),\n",
    "                               '--test_list', join_path(str(test_csv)),\n",
    "                               '--result_dir', join_path(str(result_path))\n",
    "                               ],\n",
    "#                            file_outputs = {\"result\": f\"{result_path}/loss.log\"}\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "persistent-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python PhaseNet/phasenet/train.py --mode=test --model=models --batch_size=2 --result_dir=results --test_list=test.csv --test_dir=test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "comparative-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_model(root_path: str,\n",
    "                 local_path: str,\n",
    "                 remote_path:str = \"phasenet\",\n",
    "                 bucket_name:str = \"models\",\n",
    "                 s3_url:str = \"localhost:9000\", \n",
    "                 secure:bool = True):\n",
    "    \n",
    "    import os\n",
    "    from minio import Minio\n",
    "    minioClient = Minio(s3_url,\n",
    "                  access_key='minio',\n",
    "                  secret_key='minio123',\n",
    "                  secure=secure)\n",
    "    if not minioClient.bucket_exists(bucket_name):\n",
    "        minioClient.make_bucket(bucket_name)\n",
    "    \n",
    "    for f in os.listdir(os.path.join(root_path, local_path)):\n",
    "        if os.path.isfile(os.path.join(root_path, local_path, f)):\n",
    "            minioClient.fput_object(bucket_name, os.path.join(remote_path, f), os.path.join(root_path, local_path, f))\n",
    "            print(f\"upload {os.path.join(root_path, local_path, f)} to {os.path.join(remote_path, f)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chemical-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_model(\"./\", \"PhaseNet/model/190703-214543\", s3_url=\"localhost:9000\", secure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "neither-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_model_op = comp.func_to_container_op(upload_model, \n",
    "                                            base_image='python:3.7',\n",
    "                                            packages_to_install= [\n",
    "                                                \"pandas\",\n",
    "                                                \"minio\"\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "entitled-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quakeflow_training(root_path:str, model_path:str, bucket_name:str, s3_url:str, secure:bool):\n",
    "    \n",
    "    vop_ = dsl.VolumeOp(name=\"Create_volume\", resource_name=\"data-volume\", size=\"10Gi\", modes=dsl.VOLUME_MODE_RWO).set_display_name('Persistent Volume')\n",
    "    \n",
    "    download_ = download_dataset_op(root_path).add_pvolumes({root_path: vop_.volume}).set_display_name('Download Datasets')\n",
    "    \n",
    "    train_ = training_op(root_path, model_path).add_pvolumes({root_path: download_.pvolume}).set_display_name('Training').set_gpu_limit(1)\n",
    "    train_.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    \n",
    "    test_ = test_op(root_path, model_path=model_path).add_pvolumes({root_path: train_.pvolume}).set_display_name('Inference')\n",
    "#     test_.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n",
    "    \n",
    "#     with dsl.Condition(test_.output > 0.9):\n",
    "    upload_ = upload_model_op(root_path, model_path, bucket_name=bucket_name, s3_url=s3_url, secure=secure).add_pvolumes({root_path: test_.pvolume}).set_display_name('Upload Model')\n",
    "#         upload_.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "experienced-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = kfp.Client(host='https://45ff9cb0ebef.ngrok.io')\n",
    "client = kfp.Client(host=\"5bbb5e6223b3b3e9-dot-us-west1.pipelines.googleusercontent.com\")\n",
    "# client = kfp.Client(host='127.0.0.1:8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "simple-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://5bbb5e6223b3b3e9-dot-us-west1.pipelines.googleusercontent.com/#/experiments/details/2019a8e3-c526-4415-b9a5-a1fd4be108f3\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://5bbb5e6223b3b3e9-dot-us-west1.pipelines.googleusercontent.com/#/runs/details/cd4350c4-7133-495c-8185-013fac332420\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_name = 'QuakeFlow Training'\n",
    "pipeline_func = quakeflow_training\n",
    "run_name = pipeline_func.__name__ + '_run'\n",
    "\n",
    "arguments = {\"root_path\": \"/tmp/\",\n",
    "             \"model_path\": \"models\",\n",
    "             \"bucket_name\": \"models\",\n",
    "#              \"s3_url\": \"localhost:9000\",\n",
    "#              \"secure\": False\n",
    "             \"s3_url\": \"minio-service:9000\",\n",
    "             \"secure\": False\n",
    "             }\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func, '{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "results = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                               experiment_name=experiment_name, \n",
    "                                               run_name=run_name, \n",
    "                                               arguments=arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-chicken",
   "metadata": {},
   "source": [
    "-  To check the uploaded models\n",
    "\n",
    "kubectl port-forward -n kubeflow svc/minio-service 9000:9000\n",
    "\n",
    "Access Key: minio\n",
    "Secret Key: minio123\n",
    "\n",
    "open: http://localhost:9000/minio/models/phasenet/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-socket",
   "metadata": {},
   "source": [
    "- GPU training:\n",
    "\n",
    "https://github.com/kubeflow/pipelines/blob/master/samples/tutorials/gpu/gpu.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-algorithm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-porter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-agency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
